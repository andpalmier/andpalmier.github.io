<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=theme-color><title>Machine Learning and phishing, pt. 2: Random Forest &#183; andpalmier's blog</title><meta name=title content="Machine Learning and phishing, pt. 2: Random Forest &#183; andpalmier's blog"><meta name=description content="Tuning the Random Forest algorithm to detect phishing pages"><meta name=keywords content="Phishing,AI,Machine Learning,"><link rel=canonical href=/posts/ml-with-phishing-ep2/><meta name=author content="Andrea Palmieri (@andpalmier)"><link href=https://twitter.com/andpalmier rel=me><link href=https://bsky.app/profile/andpalmier.com rel=me><link href=https://github.com/andpalmier rel=me><link href=https://linkedin.com/in/andpalmier rel=me><link href=https://andpalmier.com/index.xml rel=me><meta property="og:url" content="/posts/ml-with-phishing-ep2/"><meta property="og:site_name" content="andpalmier's blog"><meta property="og:title" content="Machine Learning and phishing, pt. 2: Random Forest"><meta property="og:description" content="Part 2 of the Machine Learning for Phishing series: Tuning Random Forests. Exploring ensemble methods to improve the detection of malicious phishing URLs."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-17T00:00:00+00:00"><meta property="article:modified_time" content="2020-06-17T00:00:00+00:00"><meta property="article:tag" content="Phishing"><meta property="article:tag" content="AI"><meta property="article:tag" content="Machine Learning"><meta property="og:image" content="/posts/ml-with-phishing-ep2/featured.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/posts/ml-with-phishing-ep2/featured.jpg"><meta name=twitter:title content="Machine Learning and phishing, pt. 2: Random Forest"><meta name=twitter:description content="Part 2 of the Machine Learning for Phishing series: Tuning Random Forests. Exploring ensemble methods to improve the detection of malicious phishing URLs."><link type=text/css rel=stylesheet href=/css/main.bundle.min.fc6219bc90238fee9b0eacb5e869ac71f831ea2c8a66ec98a69af1340225acff76762eaefad6190b02283789da553fedfc3768741dcddde07f10fc86e50eba49.css integrity="sha512-/GIZvJAjj+6bDqy16Gmscfgx6iyKZuyYpprxNAIlrP92di6u+tYZCwIoN4naVT/t/DdodB3N3eB/EPyG5Q66SQ=="><script type=text/javascript src=/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js integrity="sha512-b0EXSzoFtoCCD+CMrb+l+3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script><script src=/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7+kfJ6kKCJxQGC+8wm+Bz9JucDjDTGNew=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.0e2e7ce1e319db5369cd4badb8265de52c78d08df54617521bdac9c8cd335eea6133a82c83f9cb19baf67b8133335130e7e8ff7cfeaf7171016648dbf5a0578a.js integrity="sha512-Di584eMZ21NpzUutuCZd5Sx40I31RhdSG9rJyM0zXuphM6gsg/nLGbr2e4EzM1Ew5+j/fP6vcXEBZkjb9aBXig==" data-copy=Copy data-copied=Copied></script><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><link rel=stylesheet href=/css/repo-cards.min.baaf512416b3dfd1e3a95a3f3d8d49e978f267c0efded75be3635a9fd4655746757c1277a3a67d77c541de80b862394f6aacc26b32d3c09fb016a071661253e9.css integrity="sha512-uq9RJBaz39HjqVo/PY1J6XjyZ8Dv3tdb42Nan9RlV0Z1fBJ3o6Z9d8VB3oC4YjlPaqzCazLTwJ+wFqBxZhJT6Q=="><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Machine Learning and phishing, pt. 2: Random Forest","headline":"Machine Learning and phishing, pt. 2: Random Forest","description":"Part 2 of the Machine Learning for Phishing series: Tuning Random Forests. Exploring ensemble methods to improve the detection of malicious phishing URLs.","inLanguage":"en","url":"/posts/ml-with-phishing-ep2/","author":{"@type":"Person","name":"Andrea Palmieri (@andpalmier)"},"copyrightYear":"2020","dateCreated":"2020-06-17T00:00:00\u002b00:00","datePublished":"2020-06-17T00:00:00\u002b00:00","dateModified":"2020-06-17T00:00:00\u002b00:00","keywords":["random forest","machine learning","phishing analysis","AI security","ensemble learning","cybersecurity automation"],"mainEntityOfPage":"true","wordCount":"2591"}]</script></head><body class="flex flex-col h-screen m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32 text-lg bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral bf-scrollbar"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 bg-neutral dark:bg-neutral-800 z-100"><div class="relative m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32"><div class="main-menu flex items-center w-full gap-2 p-1 pl-0"><a href=/ class="text-base font-medium truncate min-w-0 shrink">andpalmier&rsquo;s blog</a><div class="flex items-center ms-auto"><div class="hidden md:flex"><nav class="flex items-center gap-x-5 h-12"><a href=/ class="flex items-center bf-icon-color-hover" aria-label=Home title="andpalmier's blog"><span class="text-base font-medium break-normal">Home
</span></a><a href=/about/ class="flex items-center bf-icon-color-hover" aria-label=About title="Hey ðŸ‘‹"><span class="text-base font-medium break-normal">About
</span></a><button id=search-button aria-label=Search class="text-base bf-icon-color-hover" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base bf-icon-color-hover"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav></div><div class="flex md:hidden"><div class="flex items-center h-14 gap-4"><button id=search-button-mobile aria-label=Search class="flex items-center justify-center bf-icon-color-hover" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile type=button aria-label="Dark mode switcher" class="flex items-center justify-center text-neutral-900 hover:text-primary-600 dark:text-neutral-200 dark:hover:text-primary-400"><div class=dark:hidden><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="hidden dark:block"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button>
<input type=checkbox id=mobile-menu-toggle autocomplete=off class="hidden peer">
<label for=mobile-menu-toggle class="flex items-center justify-center cursor-pointer bf-icon-color-hover"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></label><div role=dialog aria-modal=true style=scrollbar-gutter:stable class="fixed inset-0 z-50 invisible overflow-y-auto px-6 py-20 opacity-0 transition-[opacity,visibility] duration-300 peer-checked:visible peer-checked:opacity-100 bg-neutral-50/97 dark:bg-neutral-900/99
bf-scrollbar"><label for=mobile-menu-toggle class="fixed end-8 top-5 flex items-center justify-center z-50 h-12 w-12 cursor-pointer select-none rounded-full bf-icon-color-hover border bf-border-color bf-border-color-hover bg-neutral-50 dark:bg-neutral-900"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></label><nav class="mx-auto max-w-md space-y-6"><div class=px-2><a href=/ aria-label=Home class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200"><span title="andpalmier's blog" class="text-2xl font-bold tracking-tight">Home</span></a></div><div class=px-2><a href=/about/ aria-label=About class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200"><span title="Hey ðŸ‘‹" class="text-2xl font-bold tracking-tight">About</span></a></div></nav></div></div></div></div></div><script>(function(){var t,n,e=document.querySelector(".main-menu");if(!e)return;t=window.location.pathname,n=e.querySelectorAll('a[href="'+t+'"]'),n.forEach(function(e){var t=e.querySelectorAll("span");t.forEach(function(e){e.classList.add("active")})})})()</script></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><figure><img src=/posts/ml-with-phishing-ep2/featured_hu_c6155b544e79a4c8.jpg alt="Machine Learning and phishing, pt. 2: Random Forest" loading=eager decoding=async fetchpriority=high class="w-full rounded-lg single_hero_round nozoom"></figure><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class=hidden><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/>andpalmier's blog</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/posts/>Posts</a><span class="px-1 text-primary-500">/</span></li><li class=hidden><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/posts/ml-with-phishing-ep2/>Machine Learning and phishing, pt. 2: Random Forest</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Machine Learning and phishing, pt. 2: Random Forest</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2020-06-17T00:00:00+00:00>17 June 2020</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">13 mins</span></div><div class="flex flex-row flex-wrap items-center"></div></div><div class="flex author"><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Andrea Palmieri (@andpalmier)</div><div class="text-sm text-neutral-700 dark:text-neutral-400">Deep dives into malware, phishing, and threat intelligence. Eternal noob and AS Roma fan.</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/andpalmier target=_blank aria-label=Twitter title=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://bsky.app/profile/andpalmier.com target=_blank aria-label=Bluesky title=Bluesky rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg></span></span></a>
<a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/andpalmier target=_blank aria-label=Github title=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://linkedin.com/in/andpalmier target=_blank aria-label=Linkedin title=Linkedin rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://andpalmier.com/index.xml target=_blank aria-label=Rss title=Rss rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M0 64C0 46.3 14.3 32 32 32c229.8.0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7.0 64zM128 416c0 35.3-28.7 64-64 64S0 451.3.0 416s28.7-64 64-64 64 28.7 64 64zM32 160c159.1.0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7.0-32-14.3-32-32s14.3-32 32-32z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ms-auto px-0 lg:order-last lg:ps-8 lg:max-w-2xs"><div class="toc ps-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-auto overscroll-contain bf-scrollbar rounded-lg -ms-5 ps-5 pe-2 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#random-forest-against-phishing>Random forest against phishing</a></li><li><a href=#getting-ready>Getting ready</a></li><li><a href=#choose-the-best-criterion>Choose the best criterion</a></li><li><a href=#tuning-n_estimators>Tuning: n_estimators</a></li><li><a href=#tuning-max_depth>Tuning: max_depth</a></li><li><a href=#tuning-min_samples_split>Tuning: min_samples_split</a></li><li><a href=#tuning-min_samples_leaf>Tuning: min_samples_leaf</a></li><li><a href=#tuning-max_features>Tuning: max_features</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg -ms-5 ps-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#random-forest-against-phishing>Random forest against phishing</a></li><li><a href=#getting-ready>Getting ready</a></li><li><a href=#choose-the-best-criterion>Choose the best criterion</a></li><li><a href=#tuning-n_estimators>Tuning: n_estimators</a></li><li><a href=#tuning-max_depth>Tuning: max_depth</a></li><li><a href=#tuning-min_samples_split>Tuning: min_samples_split</a></li><li><a href=#tuning-min_samples_leaf>Tuning: min_samples_leaf</a></li><li><a href=#tuning-max_features>Tuning: max_features</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details><script>(function(){"use strict";const s=.33,o="#TableOfContents",i=".anchor",a='a[href^="#"]',r="li ul",c="active";let t=!1;function l(e,n){const o=window.scrollY+window.innerHeight*n,i=[...document.querySelectorAll('#TableOfContents a[href^="#"]')],s=new Set(i.map(e=>e.getAttribute("href").substring(1)));if(t)for(let t=0;t<e.length;t++){const n=e[t];if(!s.has(n.id))continue;const o=n.getBoundingClientRect().top+window.scrollY;if(Math.abs(window.scrollY-o)<100)return n.id}for(let t=e.length-1;t>=0;t--){const n=e[t].getBoundingClientRect().top+window.scrollY;if(n<=o&&s.has(e[t].id))return e[t].id}return e.find(e=>s.has(e.id))?.id||""}function e({toc:e,anchors:t,links:n,scrollOffset:s,collapseInactive:o}){const i=l(t,s);if(!i)return;if(n.forEach(e=>{const t=e.getAttribute("href")===`#${i}`;if(e.classList.toggle(c,t),o){const n=e.closest("li")?.querySelector("ul");n&&(n.style.display=t?"":"none")}}),o){const n=e.querySelector(`a[href="#${CSS.escape(i)}"]`);let t=n;for(;t&&t!==e;)t.tagName==="UL"&&(t.style.display=""),t.tagName==="LI"&&t.querySelector("ul")?.style.setProperty("display",""),t=t.parentElement}}function n(){const n=document.querySelector(o);if(!n)return;const l=!0,u=[...document.querySelectorAll(i)],d=[...n.querySelectorAll(a)];l&&n.querySelectorAll(r).forEach(e=>e.style.display="none"),d.forEach(e=>{e.addEventListener("click",()=>{t=!0})});const c={toc:n,anchors:u,links:d,scrollOffset:s,collapseInactive:l};window.addEventListener("scroll",()=>e(c),{passive:!0}),window.addEventListener("hashchange",()=>e(c),{passive:!0}),e(c)}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",n):n()})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><p>I started hunting and reporting phishing pages on Twitter, follow me <a href=https://twitter.com/andpalmier target=_blank rel=noreferrer>here</a> if you are interested! After some digging, I have decided that it would be interesting to use this topic to refresh my memory around the basics of Machine Learning.</p><h2 class="relative group">Introduction<div id=introduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#introduction aria-label=Anchor>#</a></span></h2><p>In the last post of this series, we analyzed how some of the parameters of a decision tree could improve the accuracy of the model when classifying phishing sites.</p><section class="space-y-10 w-full"><article class="article-link--shortcode flex flex-col md:flex-row relative overflow-hidden rounded-lg border border-neutral-300 dark:border-neutral-600"><div class="flex-none relative overflow-hidden thumbnail"><img src=/posts/ml-with-phishing-ep1/featured_hu_fefad0f9c1d260f1.jpg role=presentation loading=lazy decoding=async class="not-prose absolute inset-0 w-full h-full object-cover"></div><div class="p-4 pt-2"><header class="items-center text-start text-xl font-semibold"><a href=/posts/ml-with-phishing-ep1/ class="not-prose before:absolute before:inset-0 decoration-primary-500 dark:text-neutral text-xl font-bold text-neutral-800 hover:underline hover:underline-offset-2"><h2>Machine Learning and phishing, pt. 1: Decision Trees</h2></a></header><div class="text-sm text-neutral-500 dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime=2020-05-09T00:00:00+00:00>9 May 2020</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">10 mins</span></div><div class="flex flex-row flex-wrap items-center"></div></div></div></article></section><p>In this second post, we will perform a similar analysis, but with a different classifier: random forest.</p><p>A random forest classifier is made of a number of decision trees which operate as an ensemble. The idea behind random forest is simple: every tree in the forest works independently as a classifier; then - based on the task which was submitted - the prediction of the forest is either the average of the predictions of the trees or the one with the most votes.</p><figure><img class="my-0 rounded-md" src=/images/posts/ml-with-phishing/ep2/randomforest.webp alt="Schema of the random forest algorithm"><figcaption>Random forest in action</figcaption></figure><h2 class="relative group">Random forest against phishing<div id=random-forest-against-phishing class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#random-forest-against-phishing aria-label=Anchor>#</a></span></h2><p>We will start the analysis by importing the libraries and the dataset which are going to be used in this post:</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib.legend_handler</span> <span class=kn>import</span> <span class=n>HandlerLine2D</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestClassifier</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the data from a CSV file</span>
</span></span><span class=line><span class=cl><span class=n>train_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>genfromtxt</span><span class=p>(</span><span class=s1>&#39;phishing_smaller.csv&#39;</span><span class=p>,</span> <span class=n>delimiter</span><span class=o>=</span><span class=s1>&#39;,&#39;</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span></span></span></code></pre></div></div><p>Our dataset contains 10.000 samples and 11 columns, where 10 represent the features and the last one is the label of the sample.</p><p>As for the previous episode, I used a smaller version of a dataset which was created for <a href=https://www.sciencedirect.com/science/article/pii/S0020025519300763 target=_blank rel=noreferrer>this study</a>. You can find the version of the dataset used in this post here:</p><div class=github-card-wrapper><a id=github-1d6671af4f2f257bd86ac74a3a57dc82 target=_blank href=https://github.com/andpalmier/MLWithPhishing class=cursor-pointer><div class="w-full md:w-auto p-0 m-0 border border-neutral-200 dark:border-neutral-700 border rounded-md shadow-2xl"><div class="w-full nozoom"><img src=https://opengraph.githubassets.com/0/andpalmier/MLWithPhishing alt="GitHub Repository Thumbnail" class="nozoom mt-0 mb-0 w-full h-full object-cover"></div><div class="w-full md:w-auto pt-3 p-5"><div class="flex items-center"><span class="text-2xl text-neutral-800 dark:text-neutral me-2"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><div id=github-1d6671af4f2f257bd86ac74a3a57dc82-full_name class="m-0 font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral">andpalmier/MLWithPhishing</div></div><p id=github-1d6671af4f2f257bd86ac74a3a57dc82-description class="m-0 mt-2 text-md text-neutral-800 dark:text-neutral">Machine Learning basics with phishing dataset</p><div class="m-0 mt-2 flex items-center"><span class="mr-1 inline-block h-3 w-3 rounded-full language-dot" data-language="Jupyter Notebook"></span><div class="m-0 mr-5 text-md text-neutral-800 dark:text-neutral">Jupyter Notebook</div><span class="text-md mr-1 text-neutral-800 dark:text-neutral"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentColor" d="M287.9.0C297.1.0 305.5 5.25 309.5 13.52L378.1 154.8l153.3 22.7C540.4 178.8 547.8 185.1 550.7 193.7 553.5 202.4 551.2 211.9 544.8 218.2L433.6 328.4l26.3 155.5C461.4 492.9 457.7 502.1 450.2 507.4 442.8 512.7 432.1 513.4 424.9 509.1L287.9 435.9 150.1 509.1C142.9 513.4 133.1 512.7 125.6 507.4 118.2 502.1 114.5 492.9 115.1 483.9l27.1-155.5L31.11 218.2C24.65 211.9 22.36 202.4 25.2 193.7 28.03 185.1 35.5 178.8 44.49 177.5L197.7 154.8 266.3 13.52C270.4 5.249 278.7.0 287.9.0zm0 78.95L235.4 187.2C231.9 194.3 225.1 199.3 217.3 200.5L98.98 217.9 184.9 303C190.4 308.5 192.9 316.4 191.6 324.1L171.4 443.7l105.2-56.2C283.7 383.7 292.2 383.7 299.2 387.5l105.2 56.2-20.2-119.6C382.9 316.4 385.5 308.5 391 303l85.9-85.1-118.3-17.4C350.7 199.3 343.9 194.3 340.5 187.2L287.9 78.95z"/></svg></span></span><div id=github-1d6671af4f2f257bd86ac74a3a57dc82-stargazers class="m-0 mr-5 text-md text-neutral-800 dark:text-neutral">10</div><span class="text-md mr-1 text-neutral-800 dark:text-neutral"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M80 104c13.3.0 24-10.7 24-24S93.3 56 80 56 56 66.7 56 80s10.7 24 24 24zm80-24c0 32.8-19.7 61-48 73.3V192c0 17.7 14.3 32 32 32H304c17.7.0 32-14.3 32-32V153.3C307.7 141 288 112.8 288 80c0-44.2 35.8-80 80-80s80 35.8 80 80c0 32.8-19.7 61-48 73.3V192c0 53-43 96-96 96H256v70.7c28.3 12.3 48 40.5 48 73.3.0 44.2-35.8 80-80 80s-80-35.8-80-80c0-32.8 19.7-61 48-73.3V288H144c-53 0-96-43-96-96V153.3C19.7 141 0 112.8.0 80 0 35.8 35.8.0 80 0s80 35.8 80 80zm208 24c13.3.0 24-10.7 24-24s-10.7-24-24-24-24 10.7-24 24 10.7 24 24 24zM248 432c0-13.3-10.7-24-24-24s-24 10.7-24 24 10.7 24 24 24 24-10.7 24-24z"/></svg></span></span><div id=github-1d6671af4f2f257bd86ac74a3a57dc82-forks class="m-0 mr-5 text-md text-neutral-800 dark:text-neutral">6</div></div></div></div><script async type=text/javascript src=/js/fetch-repo.min.dc5533c50cefd50405344b235937142271f26229fe39cbee27fd4960e8bb897a0beebfad77a1091ca91cd0d1fb14e70fc37cc114dd9674fb2c32e0ab512ec8a4.js integrity="sha512-3FUzxQzv1QQFNEsjWTcUInHyYin+OcvuJ/1JYOi7iXoL7r+td6EJHKkc0NH7FOcPw3zBFN2WdPssMuCrUS7IpA==" data-repo-url=https://api.github.com/repos/andpalmier/MLWithPhishing data-repo-id=github-1d6671af4f2f257bd86ac74a3a57dc82></script></a></div><p>the repo contains also information about the features selected and the code of this post in form of a Jupyter notebook.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># inputs are in all columns except the last one</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>train_data</span><span class=p>[:,:</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># outputs in the last column</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>train_data</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span></span></span></code></pre></div></div><p><code>StratifiedKFold</code> will be used in order to keep the frequency of the classes constant during our k-fold cross-validation. It is important to note that <code>random_state</code> is set not only for the k-fold validation, but also in the random forest classifier: this will ensure a reproducible setup for all iterations of the model.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>StratifiedKFold</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># use 10-fold with random_state set to 0</span>
</span></span><span class=line><span class=cl><span class=n>skf</span> <span class=o>=</span> <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></span></span></code></pre></div></div><p>As in the other post, we will use AUC (Area Under Curve) to evaluate the accuracy of our classifier; so let&rsquo;s import the required library and define the array to store the accuracy during the iterations with the different folds:</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># library for evaluating the classifier</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sklearn.metrics</span> <span class=k>as</span> <span class=nn>metrics</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># list to store the accuracy during k-fold cross-validation</span>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([])</span></span></span></code></pre></div></div><p>We will now loop through the 10 splits and use them to train and evaluate 10 different models. The accuracy of these models will be stored in the <code>accuracy</code> list.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># loop with splits</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>train_index</span><span class=p>,</span> <span class=n>test_index</span> <span class=ow>in</span> <span class=n>skf</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>outputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 9 folds used for training</span>
</span></span><span class=line><span class=cl>    <span class=n>x_train</span><span class=p>,</span> <span class=n>x_test</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=n>train_index</span><span class=p>],</span> <span class=n>inputs</span><span class=p>[</span><span class=n>test_index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1 fold for testing</span>
</span></span><span class=line><span class=cl>    <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=n>train_index</span><span class=p>],</span> <span class=n>outputs</span><span class=p>[</span><span class=n>test_index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Creates the classifier</span>
</span></span><span class=line><span class=cl>    <span class=c1># random_state is to keep same setup</span>
</span></span><span class=line><span class=cl>    <span class=c1># n_jobs is -1 to use all the processors</span>
</span></span><span class=line><span class=cl>    <span class=n>rf</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Train the classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>rf</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Test the classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>rf</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>false_positives</span><span class=p>,</span> <span class=n>true_positives</span><span class=p>,</span> <span class=n>thresholds</span> <span class=o>=</span> \
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=o>.</span><span class=n>roc_curve</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># calculate classifier accuracy</span>
</span></span><span class=line><span class=cl>    <span class=n>ROC_AUC</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>auc</span><span class=p>(</span><span class=n>false_positives</span><span class=p>,</span> <span class=n>true_positives</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>accuracy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>accuracy</span><span class=p>,</span><span class=n>ROC_AUC</span><span class=p>)</span></span></span></code></pre></div></div><p>The <code>n_jobs</code> parameter of the classifier defines the number of jobs to run in parallel over the trees. If set to <code>None</code> (which is the case by default) it means 1, while if set to -1 it will use all processors.</p><p>In order to evaluate our model trained with k-folds, we will take the mean of the accuracy of the 10 values generated in the previous steps:</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;ROC AUC: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>accuracy</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div></div><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>&gt; ROC AUC: 0.922092384769539</span></span></code></pre></div></div><p>The accuracy obtained is already quite good. In fact, it is better than the one obtained with the &lsquo;vanilla&rsquo; decision tree. Let&rsquo;s see which parameters could be used to improve the performance of our random forest.</p><h2 class="relative group">Getting ready<div id=getting-ready class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#getting-ready aria-label=Anchor>#</a></span></h2><p>Before continuing with the analysis, considering that some actions are going to be repeated (training, testing and evaluate the classifiers) let&rsquo;s wrap them in a function which will be called in the next paragraphs.</p><p>Our <code>magic</code> function will take in input a list of classifiers and two lists for the results of the training and testing. The lists for the results will be filled with the values of the AUC during the k-fold iterations and will be returned at the end of the function.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># function which takes as input a list of classifiers</span>
</span></span><span class=line><span class=cl><span class=c1># and two lists for the accuracy of the classifiers</span>
</span></span><span class=line><span class=cl><span class=c1># these 2 lists will be returned in the end</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>magic</span><span class=p>(</span><span class=n>list_classifiers</span><span class=p>,</span> <span class=n>list_train_accuracy</span><span class=p>,</span> <span class=n>list_test_accuracy</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># create the folds (always the same with random_state = 0)</span>
</span></span><span class=line><span class=cl>    <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>train_index</span><span class=p>,</span> <span class=n>test_index</span> <span class=ow>in</span> <span class=n>skf</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>outputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>x_train</span><span class=p>,</span> <span class=n>x_test</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=n>train_index</span><span class=p>],</span> <span class=n>inputs</span><span class=p>[</span><span class=n>test_index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=n>train_index</span><span class=p>],</span> <span class=n>outputs</span><span class=p>[</span><span class=n>test_index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1># iterate through the classifiers</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=nb>len</span><span class=p>(</span><span class=n>list_classifiers</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	    <span class=n>classifier</span> <span class=o>=</span> <span class=n>list_classifiers</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	    <span class=n>classifier</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	    <span class=c1># get train accuracy</span>
</span></span><span class=line><span class=cl>	    <span class=n>predictions</span> <span class=o>=</span> <span class=n>classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	    <span class=n>false_positives</span><span class=p>,</span> <span class=n>true_positives</span><span class=p>,</span> <span class=n>threshold</span> <span class=o>=</span> \
</span></span><span class=line><span class=cl>		<span class=n>metrics</span><span class=o>.</span><span class=n>roc_curve</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	    <span class=n>ROC_AUC</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>auc</span><span class=p>(</span><span class=n>false_positives</span><span class=p>,</span><span class=n>true_positives</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	    <span class=n>list_train_accuracy</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>list_train_accuracy</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>ROC_AUC</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	    <span class=c1># get test accuracy</span>
</span></span><span class=line><span class=cl>	    <span class=n>predictions</span> <span class=o>=</span> <span class=n>classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	    <span class=n>false_positives</span><span class=p>,</span> <span class=n>true_positives</span><span class=p>,</span> <span class=n>threshold</span> <span class=o>=</span> \
</span></span><span class=line><span class=cl>		<span class=n>metrics</span><span class=o>.</span><span class=n>roc_curve</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	    <span class=n>ROC_AUC</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>auc</span><span class=p>(</span><span class=n>false_positives</span><span class=p>,</span><span class=n>true_positives</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	    <span class=n>list_test_accuracy</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>list_test_accuracy</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>ROC_AUC</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># return the array of accuracy of the classifiers</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>list_train_accuracy</span><span class=p>,</span><span class=n>list_test_accuracy</span></span></span></code></pre></div></div><h2 class="relative group">Choose the best criterion<div id=choose-the-best-criterion class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#choose-the-best-criterion aria-label=Anchor>#</a></span></h2><p>If you want to see the full list of parameters available to tune the random forest classifier, please refer to <a href=https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html target=_blank rel=noreferrer>the scikit-learn documentation for random forest</a>.</p><p>We will start our analysis with the <code>criterion</code> parameter, which represents the function that will be used to measure the quality of a split. The supported criteria are <code>gini</code> (for <a href=https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity target=_blank rel=noreferrer>Gini impurity</a>) and <code>entropy</code> (for <a href=https://en.wikipedia.org/wiki/Information_gain_in_decision_trees target=_blank rel=noreferrer>information gain</a>).</p><p>We will now create two classifiers having different <code>criterion</code>, to see which one has the best accuracy with our dataset.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># create the two classifiers</span>
</span></span><span class=line><span class=cl><span class=n>gini_classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> \
</span></span><span class=line><span class=cl>    <span class=n>criterion</span><span class=o>=</span><span class=s2>&#34;gini&#34;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>entropy_classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> \
</span></span><span class=line><span class=cl>    <span class=n>criterion</span><span class=o>=</span><span class=s2>&#34;entropy&#34;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># lists to store variables to pass to the &#34;magic&#34; function</span>
</span></span><span class=line><span class=cl><span class=n>classifiers</span> <span class=o>=</span> <span class=p>[</span><span class=n>gini_classifier</span><span class=p>,</span><span class=n>entropy_classifier</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>train_accuracies</span> <span class=o>=</span> <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]),</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([])]</span>
</span></span><span class=line><span class=cl><span class=n>test_accuracies</span> <span class=o>=</span> <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]),</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([])]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># in this iteration we are interested only in the test results</span>
</span></span><span class=line><span class=cl><span class=n>_</span><span class=p>,</span><span class=n>test_results</span> <span class=o>=</span> <span class=n>magic</span><span class=p>(</span><span class=n>classifiers</span><span class=p>,</span><span class=n>train_accuracies</span><span class=p>,</span><span class=n>test_accuracies</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy of gini classifier: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>test_results</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy of entropy classifier: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>test_results</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=n>Accuracy</span> <span class=n>of</span> <span class=n>gini</span> <span class=n>classifier</span><span class=p>:</span> <span class=mf>0.922092384769539</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=n>Accuracy</span> <span class=n>of</span> <span class=n>entropy</span> <span class=n>classifier</span><span class=p>:</span> <span class=mf>0.9227925851703407</span></span></span></code></pre></div></div><p>The results listed above shows that, even if the difference is not much (0.07%), the classifier using the entropy function as a criterion for the split outperforms the one using the gini function. It is interesting to note that the gini criterion is the one used by default for decision trees in sklearn.</p><h2 class="relative group">Tuning: n_estimators<div id=tuning-n_estimators class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#tuning-n_estimators aria-label=Anchor>#</a></span></h2><p>Now we are going to tune <code>n_estimators</code>, which represents the total number of trees in the forest. Having a high number of trees usually has the advantage of increasing the overall accuracy of the model, however it will make the training phase slower due to the fact that a higher number of trees needs to be trained.
By default, <code>n_estimators</code> is set to 100 (before version 0.22 of sklearn it was 10).</p><p>In the following example, we will create and evaluate 8 different classifiers having <code>n_estimators</code> set to 1, 3, 6, 10, 25, 50, 75, 100, 125 and 150.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># number of estimators to use in the 10 classifiers</span>
</span></span><span class=line><span class=cl><span class=n>n_estimators</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>6</span><span class=p>,</span><span class=mi>10</span><span class=p>,</span><span class=mi>25</span><span class=p>,</span><span class=mi>50</span><span class=p>,</span><span class=mi>75</span><span class=p>,</span><span class=mi>100</span><span class=p>,</span><span class=mi>125</span><span class=p>,</span><span class=mi>150</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># lists to use for the &#34;magic&#34; function</span>
</span></span><span class=line><span class=cl><span class=n>classifiers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>train_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>test_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>n_estimators</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># create classifier with appropriate n_estimators</span>
</span></span><span class=line><span class=cl>    <span class=n>classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>n_estimators</span><span class=o>=</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>classifiers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>classifier</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># metrics to evaluate the classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>train_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>    <span class=n>test_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># let the magic happen</span>
</span></span><span class=line><span class=cl><span class=n>train_results</span><span class=p>,</span><span class=n>test_results</span> <span class=o>=</span> <span class=n>magic</span><span class=p>(</span><span class=n>classifiers</span><span class=p>,</span><span class=n>test_accuracies</span><span class=p>,</span><span class=n>train_accuracies</span><span class=p>)</span></span></span></code></pre></div></div><p>The <code>magic</code> function returned two lists containing the accuracy for every iteration of k-fold for every classifier; now the average of the accuracy for each random forest will be taken, in order to show the results in a chart using <a href=https://matplotlib.org/ target=_blank rel=noreferrer>matplotlib</a>.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># store the averages of the classifiers for training and testing</span>
</span></span><span class=line><span class=cl><span class=n>avg_train</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>avg_test</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># loop for every classifier we created</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=nb>len</span><span class=p>(</span><span class=n>train_results</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># average the results for every classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_train</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>train_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_test</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>test_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># blue line for train AUC</span>
</span></span><span class=line><span class=cl><span class=n>line1</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>n_estimators</span><span class=p>,</span> <span class=n>avg_train</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Train AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># red line for test AUC</span>
</span></span><span class=line><span class=cl><span class=n>line2</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>n_estimators</span><span class=p>,</span> <span class=n>avg_test</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Test AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># print chart</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>handler_map</span><span class=o>=</span><span class=p>{</span><span class=n>line1</span><span class=p>:</span> <span class=n>HandlerLine2D</span><span class=p>(</span><span class=n>numpoints</span><span class=o>=</span><span class=mi>2</span><span class=p>)})</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;AUC score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><figure><img class="my-0 rounded-md" src=/images/posts/ml-with-phishing/ep2/nestimators.webp alt="n estimators chart"><figcaption>Performance of the model when tuning n_estimators</figcaption></figure><p>For our dataset, the best accuracy in the tests is achieved when using 50 trees (92,29%). If we further increase the number of trees, the AUC in the tests will slightly decrease. The same number of trees allows the classifier to reach the maximum accuracy during training (almost 95%).</p><h2 class="relative group">Tuning: max_depth<div id=tuning-max_depth class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#tuning-max_depth aria-label=Anchor>#</a></span></h2><p><code>max_depth</code> is used to specify the maximum depth of each tree in the forest. As we saw in our previous analysis, the deeper the tree, the more splits it has; thus it will be able to capure more information about the data.</p><p>The ranges of the <code>max_depth</code> for our analysis will be between 1 and 32. As in the previous paragraph, a line chart will be used to show the results.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># max depths to use in the classifiers</span>
</span></span><span class=line><span class=cl><span class=n>list_max_depth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=n>endpoint</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># lists to use in the magic function</span>
</span></span><span class=line><span class=cl><span class=n>classifiers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>train_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>test_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>list_max_depth</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># create classifier with appropriate max_depth</span>
</span></span><span class=line><span class=cl>    <span class=n>classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>max_depth</span><span class=o>=</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>classifiers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>classifier</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># metrics to evaluate the classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>train_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>    <span class=n>test_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># let the magic happen</span>
</span></span><span class=line><span class=cl><span class=n>train_results</span><span class=p>,</span><span class=n>test_results</span> <span class=o>=</span> <span class=n>magic</span><span class=p>(</span><span class=n>classifiers</span><span class=p>,</span><span class=n>test_accuracies</span><span class=p>,</span><span class=n>train_accuracies</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># store the averages of the classifiers for training and testing</span>
</span></span><span class=line><span class=cl><span class=n>avg_training</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>avg_testing</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=nb>len</span><span class=p>(</span><span class=n>train_results</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># average the results for every classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_training</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>train_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_testing</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>test_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># blue line for train AUC</span>
</span></span><span class=line><span class=cl><span class=n>line1</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_max_depth</span><span class=p>,</span> <span class=n>avg_training</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Train AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># red line for test AUC</span>
</span></span><span class=line><span class=cl><span class=n>line2</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_max_depth</span><span class=p>,</span> <span class=n>avg_testing</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Test AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># print chart</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>handler_map</span><span class=o>=</span><span class=p>{</span><span class=n>line1</span><span class=p>:</span> <span class=n>HandlerLine2D</span><span class=p>(</span><span class=n>numpoints</span><span class=o>=</span><span class=mi>2</span><span class=p>)})</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;AUC score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;max_depths&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><figure><img class="my-0 rounded-md" src=/images/posts/ml-with-phishing/ep2/maxdepth.webp alt="max depth chart"><figcaption>Performance of the model when tuning max_depth</figcaption></figure><p>It is interesting to note the spike that is generated when increasing the <code>max_depth</code> of the trees in the forest from 2 to 3: the AUC in training and testing improves of almost 10% (from around 0.8 to almost 0.9).</p><p>As expected, <code>max_depth</code> contributes to an improvement of the overall accuracy of the model, until around 13, when the test AUC reach its peak. The best AUC during training is reached at 15, and remains stable even when using trees with 32 splits.</p><h2 class="relative group">Tuning: min_samples_split<div id=tuning-min_samples_split class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#tuning-min_samples_split aria-label=Anchor>#</a></span></h2><p>The next parameter to be tuned is <code>min_samples_split</code>: it represents the minimum number of samples required to split a node in the trees of the forest. This parameter can be an integer (its default value is 2), but also a float: so that <code>ceil(min_samples_split * n_samples)</code> are the minimum number of samples for each split.</p><p>In this experiment will train and evaluate 10 classifiers having <code>min_samples_split</code> between 0.1 and 1.0.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># min samples splits from 10% to 100%</span>
</span></span><span class=line><span class=cl><span class=n>list_min_samples_splits</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.1</span><span class=p>,</span><span class=mf>1.0</span><span class=p>,</span><span class=mi>10</span><span class=p>,</span><span class=n>endpoint</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># lists to use in the magic function</span>
</span></span><span class=line><span class=cl><span class=n>classifiers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>train_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>test_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>list_min_samples_splits</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># create classifier with appropriate max_depth</span>
</span></span><span class=line><span class=cl>    <span class=n>classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> \
</span></span><span class=line><span class=cl>	<span class=n>min_samples_split</span><span class=o>=</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>classifiers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>classifier</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># metrics to evaluate the classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>train_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>    <span class=n>test_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># let the magic happen</span>
</span></span><span class=line><span class=cl><span class=n>train_results</span><span class=p>,</span><span class=n>test_results</span> <span class=o>=</span> <span class=n>magic</span><span class=p>(</span><span class=n>classifiers</span><span class=p>,</span><span class=n>test_accuracies</span><span class=p>,</span><span class=n>train_accuracies</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># store the averages of the classifiers for training and testing</span>
</span></span><span class=line><span class=cl><span class=n>avg_training</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>avg_testing</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=nb>len</span><span class=p>(</span><span class=n>train_results</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># average the results for every classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_training</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>train_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_testing</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>test_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># print chart</span>
</span></span><span class=line><span class=cl><span class=n>line1</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_min_samples_splits</span><span class=p>,</span> <span class=n>avg_training</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Train AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>line2</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_min_samples_splits</span><span class=p>,</span> <span class=n>avg_testing</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Test AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>handler_map</span><span class=o>=</span><span class=p>{</span><span class=n>line1</span><span class=p>:</span> <span class=n>HandlerLine2D</span><span class=p>(</span><span class=n>numpoints</span><span class=o>=</span><span class=mi>2</span><span class=p>)})</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;AUC score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;min samples splits&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><figure><img class="my-0 rounded-md" src=/images/posts/ml-with-phishing/ep2/minsamplesplits.webp alt="min samples split chart"><figcaption>Performance of the model when tuning min_samples_split</figcaption></figure><p>We can see from the results in the chart that for values of <code>min_samples_split</code> above 0.7, our model does not learn enough information from the data: this is because too many samples are required at each node in order to be split. For high values of <code>min_samples_split</code> the performances are equally bad (0.5 of AUC) during train and test.</p><h2 class="relative group">Tuning: min_samples_leaf<div id=tuning-min_samples_leaf class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#tuning-min_samples_leaf aria-label=Anchor>#</a></span></h2><p>Similarly to the previous parameter, <code>min_samples_leaf</code> it is used to specify the minimum number of samples which are required to be in a leaf of the trees in our forest. Again, this parameter can be an integer (also in this case its default value is 2) and a float, so that <code>ceil(min_samples_leaf * n_samples)</code> are the minimum number of samples for each node.</p><p>The classifiers which are defined in the following lines have <code>min_samples_split</code> between 0.05 and 0.5 (maximum number allowed).</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># min samples leaf from 5% to 50%</span>
</span></span><span class=line><span class=cl><span class=n>list_min_samples_leaf</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.05</span><span class=p>,</span><span class=mf>0.5</span><span class=p>,</span><span class=mi>10</span><span class=p>,</span><span class=n>endpoint</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># lists to use in the magic function</span>
</span></span><span class=line><span class=cl><span class=n>classifiers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>train_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>test_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>list_min_samples_leaf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># create classifier with appropriate max_depth</span>
</span></span><span class=line><span class=cl>    <span class=n>classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> \
</span></span><span class=line><span class=cl>	<span class=n>min_samples_leaf</span><span class=o>=</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>classifiers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>classifier</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># metrics to evaluate the classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>train_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>    <span class=n>test_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># let the magic happen</span>
</span></span><span class=line><span class=cl><span class=n>train_results</span><span class=p>,</span><span class=n>test_results</span> <span class=o>=</span> <span class=n>magic</span><span class=p>(</span><span class=n>classifiers</span><span class=p>,</span><span class=n>test_accuracies</span><span class=p>,</span><span class=n>train_accuracies</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># store the averages of the classifiers for training and testing</span>
</span></span><span class=line><span class=cl><span class=n>avg_training</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>avg_testing</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=nb>len</span><span class=p>(</span><span class=n>train_results</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># average the results for every classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_training</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>train_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_testing</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>test_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># print chart</span>
</span></span><span class=line><span class=cl><span class=n>line1</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_min_samples_leaf</span><span class=p>,</span> <span class=n>avg_training</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Train AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>line2</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_min_samples_leaf</span><span class=p>,</span> <span class=n>avg_testing</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Test AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>handler_map</span><span class=o>=</span><span class=p>{</span><span class=n>line1</span><span class=p>:</span> <span class=n>HandlerLine2D</span><span class=p>(</span><span class=n>numpoints</span><span class=o>=</span><span class=mi>2</span><span class=p>)})</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;AUC score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;min samples leaf&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><figure><img class="my-0 rounded-md" src=/images/posts/ml-with-phishing/ep2/minsamplesleaf.webp alt="min samples leaf chart"><figcaption>Performance of the model when tuning min_samples_leaf</figcaption></figure><p>The results are similar to the previous analysis. Increasing the value of <code>min_samples_leaf</code> cause the model to fail in learning from the data, and decrease its performance to the point of obtaining AUC of 0.5 during train and test when <code>min_samples_leaf</code> is set to more than 0.35.</p><h2 class="relative group">Tuning: max_features<div id=tuning-max_features class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#tuning-max_features aria-label=Anchor>#</a></span></h2><p>We will conclude this analysis of the random forest classifier with <code>max_features</code>. This parameter represents the number of features which are going to be considered when looking for the best possible split.</p><p>Its default value is <em>None</em>, so that <code>max_features</code> is set to the total number of features. Considering that our dataset has 10 features for every sample, we will train and test 10 classifiers having <code>max_features</code> between 1 and 10.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># max features from 1 to 10</span>
</span></span><span class=line><span class=cl><span class=n>list_max_features</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>11</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># lists to use in the magic function</span>
</span></span><span class=line><span class=cl><span class=n>classifiers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>train_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>test_accuracies</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>list_max_features</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># create classifier with appropriate max_depth</span>
</span></span><span class=line><span class=cl>    <span class=n>classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>max_features</span><span class=o>=</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>classifiers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>classifier</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># metrics to evaluate the classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>train_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>    <span class=n>test_accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># let the magic happen</span>
</span></span><span class=line><span class=cl><span class=n>train_results</span><span class=p>,</span><span class=n>test_results</span> <span class=o>=</span> <span class=n>magic</span><span class=p>(</span><span class=n>classifiers</span><span class=p>,</span><span class=n>test_accuracies</span><span class=p>,</span><span class=n>train_accuracies</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># store the averages of the classifiers for training and testing</span>
</span></span><span class=line><span class=cl><span class=n>avg_training</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>avg_testing</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=nb>len</span><span class=p>(</span><span class=n>train_results</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># average the results for every classifier</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_training</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>train_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_testing</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>test_results</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># print chart</span>
</span></span><span class=line><span class=cl><span class=n>line1</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_max_features</span><span class=p>,</span> <span class=n>avg_training</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Train AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>line2</span><span class=p>,</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>list_max_features</span><span class=p>,</span> <span class=n>avg_testing</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Test AUC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>handler_map</span><span class=o>=</span><span class=p>{</span><span class=n>line1</span><span class=p>:</span> <span class=n>HandlerLine2D</span><span class=p>(</span><span class=n>numpoints</span><span class=o>=</span><span class=mi>2</span><span class=p>)})</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;AUC score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;max features&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><figure><img class="my-0 rounded-md" src=/images/posts/ml-with-phishing/ep2/maxfeatures.webp alt="max features chart"><figcaption>Performance of the model when tuning max_features</figcaption></figure><p>The resulting chart shows that the accuracy of the model does not improve when increasing <code>max_features</code> and it causes an overfitting for all the values in the experiment.</p><p>A similar result was obtained when tuning the same parameter for the decision tree. As stated in the sklearn documentation of random forest classifiers: <em>&rsquo;the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features&rsquo;</em>.</p><h2 class="relative group">Conclusion<div id=conclusion class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#conclusion aria-label=Anchor>#</a></span></h2><p>In this post we conducted an experiment to evaluate how some of the parameters available to tune random forest classifiers affect the performance of the model when trying to detect a phishing page. The parameters explored were: <code>criterion</code>, <code>max_depth</code>, <code>min_samples_split</code>, <code>min_samples_leaf</code> and <code>max_features</code>.</p><p>I will mention again that this is not the proper way of tuning the parameters for a random forest: the best approach would be to extend parameters search using <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html target=_blank rel=noreferrer>RandomizedSearchCV</a> provided by sklearn.</p></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=/posts/ml-with-phishing-ep2/&amp;title=Machine%20Learning%20and%20phishing,%20pt.%202:%20Random%20Forest" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=/posts/ml-with-phishing-ep2/&amp;text=Machine%20Learning%20and%20phishing,%20pt.%202:%20Random%20Forest" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span>
</a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://bsky.app/intent/compose?text=Machine%20Learning%20and%20phishing,%20pt.%202:%20Random%20Forest+/posts/ml-with-phishing-ep2/" title="Post on Bluesky" aria-label="Post on Bluesky"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg></span>
</a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://s2f.kytta.dev/?text=Machine%20Learning%20and%20phishing,%20pt.%202:%20Random%20Forest%20/posts/ml-with-phishing-ep2/" title="Share via Mastodon" aria-label="Share via Mastodon"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48.0.0.0-63.72 28.5-63.72 125.7.0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54.0 01-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://reddit.com/submit/?url=/posts/ml-with-phishing-ep2/&amp;resubmit=true&amp;title=Machine%20Learning%20and%20phishing,%20pt.%202:%20Random%20Forest" title="Submit to Reddit" aria-label="Submit to Reddit"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8.0-24.9-11.1-24.9-24.6.0-13.8 11.1-24.9 24.9-24.9 13.6.0 24.6 11.1 24.6 24.9.0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4.0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7.0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9.0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5.0 52.6 59.2 95.2 132 95.2 73.1.0 132.3-42.6 132.3-95.2.0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6.0-2.2-2.2-6.1-2.2-8.3.0-2.5 2.5-2.5 6.4.0 8.6 22.8 22.8 87.3 22.8 110.2.0 2.5-2.2 2.5-6.1.0-8.6-2.2-2.2-6.1-2.2-8.3.0zm7.7-75c-13.6.0-24.6 11.1-24.6 24.9.0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.1 24.9-24.6.0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer/sharer.php?u=/posts/ml-with-phishing-ep2/&amp;quote=Machine%20Learning%20and%20phishing,%20pt.%202:%20Random%20Forest" title="Share on Facebook" aria-label="Share on Facebook"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14.0 55.52 4.84 55.52 4.84v61h-31.28c-30.8.0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></span></a></section><h2 class="mt-8 text-2xl font-extrabold mb-10">Related</h2><section class="w-full grid gap-4 sm:grid-cols-2 md:grid-cols-3"><article class="article-link--related relative min-h-full min-w-full overflow-hidden rounded-lg border border-neutral-300 dark:border-neutral-600"><div class="flex-none relative overflow-hidden thumbnail_card_related"><img src=/posts/ml-with-phishing-ep1/featured_hu_fefad0f9c1d260f1.jpg role=presentation loading=lazy decoding=async fetchpriority=low class="not-prose absolute inset-0 w-full h-full object-cover"></div><div class=p-4><header><a href=/posts/ml-with-phishing-ep1/ class="not-prose before:absolute before:inset-0 decoration-primary-500 dark:text-neutral text-xl font-bold text-neutral-800 hover:underline hover:underline-offset-2"><h2>Machine Learning and phishing, pt. 1: Decision Trees</h2></a></header><div class="text-sm text-neutral-500 dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime=2020-05-09T00:00:00+00:00>9 May 2020</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">10 mins</span></div><div class="flex flex-row flex-wrap items-center"></div></div></div><div class="px-6 pt-4 pb-2"></div></article><article class="article-link--related relative min-h-full min-w-full overflow-hidden rounded-lg border border-neutral-300 dark:border-neutral-600"><div class="flex-none relative overflow-hidden thumbnail_card_related"><img src=/posts/phishing-findings-1/featured_hu_fe8baf6cae3d4883.jpeg role=presentation loading=lazy decoding=async fetchpriority=low class="not-prose absolute inset-0 w-full h-full object-cover"></div><div class=p-4><header><a href=/posts/phishing-findings-1/ class="not-prose before:absolute before:inset-0 decoration-primary-500 dark:text-neutral text-xl font-bold text-neutral-800 hover:underline hover:underline-offset-2"><h2>Phishing findings, campaign #1: u.zip (Office365/Outlook)</h2></a></header><div class="text-sm text-neutral-500 dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime=2020-05-26T00:00:00+00:00>26 May 2020</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">7 mins</span></div><div class="flex flex-row flex-wrap items-center"></div></div></div><div class="px-6 pt-4 pb-2"></div></article><article class="article-link--related relative min-h-full min-w-full overflow-hidden rounded-lg border border-neutral-300 dark:border-neutral-600"><div class="flex-none relative overflow-hidden thumbnail_card_related"><img src=/posts/fdroid-apps/featured_hu_6e359495c63637f7.png role=presentation loading=lazy decoding=async fetchpriority=low class="not-prose absolute inset-0 w-full h-full object-cover"></div><div class=p-4><header><a href=/posts/fdroid-apps/ class="not-prose before:absolute before:inset-0 decoration-primary-500 dark:text-neutral text-xl font-bold text-neutral-800 hover:underline hover:underline-offset-2"><h2>F-Droid apps you will find useful</h2></a></header><div class="text-sm text-neutral-500 dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime=2020-04-05T00:00:00+00:00>5 April 2020</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">4 mins</span></div><div class="flex flex-row flex-wrap items-center"></div></div></div><div class="px-6 pt-4 pb-2"></div></article></section></div><script type=text/javascript src=/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA==" data-oid=views_posts/ml-with-phishing-ep2/index.md data-oid-likes=likes_posts/ml-with-phishing-ep2/index.md></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://giscus.app/client.js data-repo=andpalmier/andpalmier.github.io data-repo-id=R_kgDOGcbGMQ data-category=General data-category-id=DIC_kwDOGcbGMc4CleV- data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></div></div></footer></article><div id=scroll-to-top class="fixed bottom-6 end-6 z-50 transform translate-y-4 opacity-0 duration-200"><a href=#the-top class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">2025 - <a href=https://andpalmier.com target=_blank rel=noreferrer>andpalmier.com</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh] z-500" data-url=/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>